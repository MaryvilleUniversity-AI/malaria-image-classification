{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Grad-CAM Explainability Notebook"
      ],
      "metadata": {
        "id": "AdNp39FcWwkj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and Setup"
      ],
      "metadata": {
        "id": "sRbWPUsed0NJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input"
      ],
      "metadata": {
        "id": "zLfUWZRFd2_2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load models"
      ],
      "metadata": {
        "id": "z-1SDJM5W4KK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9a0JbI6KVcp_"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "  \"Custom CNN\": tf.keras.models.load_model('/content/models/custom_cnn.keras'),\n",
        "  \"MobileNetV2 (Frozen)\": tf.keras.models.load_model('/content/models/malaria_mobilenetv2_frozen.keras'),\n",
        "  \"MobileNetV2 (Fine-tuned)\": tf.keras.models.load_model('/content/models/malaria_mobilenetv2_frozen.keras')\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify the Last Convolutional Layer of Each Model"
      ],
      "metadata": {
        "id": "DiBWdAwHXzBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, model in models.items():\n",
        "    print(f\"{name} input shape: {model.input_shape}\")\n",
        "    print(f\"{name} last conv: {model_configs[name]['last_conv']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCNEz8gioTlQ",
        "outputId": "25f408c0-b233-499a-9509-c33d7432870e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom CNN input shape: (None, 128, 128, 3)\n",
            "Custom CNN last conv: conv2d_1\n",
            "MobileNetV2 (Frozen) input shape: (None, 128, 128, 3)\n",
            "MobileNetV2 (Frozen) last conv: Conv_1\n",
            "MobileNetV2 (Fine-tuned) input shape: (None, 128, 128, 3)\n",
            "MobileNetV2 (Fine-tuned) last conv: Conv_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Configuration Dictionary"
      ],
      "metadata": {
        "id": "Nng5dRK0eusO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_configs = {\n",
        "    \"Custom CNN\": {\n",
        "        \"input_size\": (128, 128),\n",
        "        \"preprocess\": lambda x: x / 255.0,\n",
        "        \"last_conv\": \"conv2d_1\"\n",
        "    },\n",
        "    \"MobileNetV2 (Frozen)\": {\n",
        "        \"input_size\": (128, 128),\n",
        "        \"preprocess\": tf.keras.applications.mobilenet_v2.preprocess_input,\n",
        "        \"last_conv\": \"Conv_1\"\n",
        "    },\n",
        "    \"MobileNetV2 (Fine-tuned)\": {\n",
        "        \"input_size\": (128, 128),\n",
        "        \"preprocess\": tf.keras.applications.mobilenet_v2.preprocess_input,\n",
        "        \"last_conv\": \"Conv_1\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "AH0oVOTHexC-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, model in models.items():\n",
        "    print(f\"\\n{'='*20} Checking Model: {model_name} {'='*20}\")\n",
        "\n",
        "    # Print the last 10 layers to see names and types\n",
        "    for layer in model.layers[-10:]:\n",
        "        print(f\"Layer Name: {layer.name} | Type: {type(layer)}\")\n",
        "\n",
        "    # Diagnostic: Check if the config name actually exists in this model\n",
        "    expected_layer = model_configs[model_name][\"last_conv\"]\n",
        "    try:\n",
        "        model.get_layer(expected_layer)\n",
        "        print(f\"✅ Success: '{expected_layer}' found in {model_name}.\")\n",
        "    except ValueError:\n",
        "        print(f\"❌ ERROR: '{expected_layer}' NOT found in {model_name}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pgn8oxnOse6a",
        "outputId": "40f6a86e-5f8f-43e4-9b3c-d9e6e712989a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== Checking Model: Custom CNN ====================\n",
            "Layer Name: conv2d | Type: <class 'keras.src.layers.convolutional.conv2d.Conv2D'>\n",
            "Layer Name: max_pooling2d | Type: <class 'keras.src.layers.pooling.max_pooling2d.MaxPooling2D'>\n",
            "Layer Name: conv2d_1 | Type: <class 'keras.src.layers.convolutional.conv2d.Conv2D'>\n",
            "Layer Name: max_pooling2d_1 | Type: <class 'keras.src.layers.pooling.max_pooling2d.MaxPooling2D'>\n",
            "Layer Name: flatten | Type: <class 'keras.src.layers.reshaping.flatten.Flatten'>\n",
            "Layer Name: dense | Type: <class 'keras.src.layers.core.dense.Dense'>\n",
            "Layer Name: dropout | Type: <class 'keras.src.layers.regularization.dropout.Dropout'>\n",
            "Layer Name: dense_1 | Type: <class 'keras.src.layers.core.dense.Dense'>\n",
            "✅ Success: 'conv2d_1' found in Custom CNN.\n",
            "\n",
            "==================== Checking Model: MobileNetV2 (Frozen) ====================\n",
            "Layer Name: block_16_depthwise_relu | Type: <class 'keras.src.layers.activations.relu.ReLU'>\n",
            "Layer Name: block_16_project | Type: <class 'keras.src.layers.convolutional.conv2d.Conv2D'>\n",
            "Layer Name: block_16_project_BN | Type: <class 'keras.src.layers.normalization.batch_normalization.BatchNormalization'>\n",
            "Layer Name: Conv_1 | Type: <class 'keras.src.layers.convolutional.conv2d.Conv2D'>\n",
            "Layer Name: Conv_1_bn | Type: <class 'keras.src.layers.normalization.batch_normalization.BatchNormalization'>\n",
            "Layer Name: out_relu | Type: <class 'keras.src.layers.activations.relu.ReLU'>\n",
            "Layer Name: global_average_pooling2d | Type: <class 'keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D'>\n",
            "Layer Name: dense_2 | Type: <class 'keras.src.layers.core.dense.Dense'>\n",
            "Layer Name: dropout_1 | Type: <class 'keras.src.layers.regularization.dropout.Dropout'>\n",
            "Layer Name: dense_3 | Type: <class 'keras.src.layers.core.dense.Dense'>\n",
            "✅ Success: 'Conv_1' found in MobileNetV2 (Frozen).\n",
            "\n",
            "==================== Checking Model: MobileNetV2 (Fine-tuned) ====================\n",
            "Layer Name: block_16_depthwise_relu | Type: <class 'keras.src.layers.activations.relu.ReLU'>\n",
            "Layer Name: block_16_project | Type: <class 'keras.src.layers.convolutional.conv2d.Conv2D'>\n",
            "Layer Name: block_16_project_BN | Type: <class 'keras.src.layers.normalization.batch_normalization.BatchNormalization'>\n",
            "Layer Name: Conv_1 | Type: <class 'keras.src.layers.convolutional.conv2d.Conv2D'>\n",
            "Layer Name: Conv_1_bn | Type: <class 'keras.src.layers.normalization.batch_normalization.BatchNormalization'>\n",
            "Layer Name: out_relu | Type: <class 'keras.src.layers.activations.relu.ReLU'>\n",
            "Layer Name: global_average_pooling2d | Type: <class 'keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D'>\n",
            "Layer Name: dense_2 | Type: <class 'keras.src.layers.core.dense.Dense'>\n",
            "Layer Name: dropout_1 | Type: <class 'keras.src.layers.regularization.dropout.Dropout'>\n",
            "Layer Name: dense_3 | Type: <class 'keras.src.layers.core.dense.Dense'>\n",
            "✅ Success: 'Conv_1' found in MobileNetV2 (Fine-tuned).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test if gradients can even flow through the model\n",
        "test_img = tf.convert_to_tensor(img_array, dtype=tf.float32)\n",
        "with tf.GradientTape() as tape:\n",
        "    tape.watch(test_img)\n",
        "    p = models['Custom CNN'](test_img)\n",
        "g = tape.gradient(p, test_img)\n",
        "print(\"Gradient check:\", g is not None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aG3TQ93vDFK",
        "outputId": "fa13a6fb-b6ae-46f5-da24-51592c9c37c2"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient check: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Sequential to Functional to ensure gradient connectivity\n",
        "for name in models:\n",
        "    m = models[name]\n",
        "    models[name] = tf.keras.models.Model(inputs=m.inputs, outputs=m.outputs)"
      ],
      "metadata": {
        "id": "jsMWlm5Vvs9o"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Universal Grad-CAM Function"
      ],
      "metadata": {
        "id": "scVg9NxVf-TF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
        "\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        inputs=model.inputs,\n",
        "        outputs=[last_conv_layer.output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        img_tensor = tf.cast(img_array, tf.float32)\n",
        "        # Unpack the list returned by grad_model\n",
        "        conv_outputs, predictions = grad_model(img_tensor, training=False)\n",
        "\n",
        "        # Check if predictions is a list (sometimes happens in Sequential/Nested)\n",
        "        if isinstance(predictions, list):\n",
        "            predictions = predictions[0]\n",
        "\n",
        "        # Now .shape will work\n",
        "        if predictions.shape[-1] == 1:\n",
        "            class_channel = predictions[:, 0]\n",
        "        else:\n",
        "            if pred_index is None:\n",
        "                pred_index = tf.argmax(predictions[0])\n",
        "            class_channel = predictions[:, pred_index]\n",
        "\n",
        "    # Calculate gradients\n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "\n",
        "    if grads is None:\n",
        "        # Final fallback for stubborn layers: watch the tensor directly\n",
        "        with tf.GradientTape() as tape:\n",
        "            conv_outputs, predictions = grad_model(img_tensor, training=False)\n",
        "            if isinstance(predictions, list): predictions = predictions[0]\n",
        "            tape.watch(conv_outputs)\n",
        "            class_channel = predictions[:, 0] if predictions.shape[-1] == 1 else predictions[:, pred_index]\n",
        "        grads = tape.gradient(class_channel, conv_outputs)\n",
        "\n",
        "    # Global average pooling and heatmap math\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + 1e-8)\n",
        "    return heatmap.numpy()"
      ],
      "metadata": {
        "id": "TowCxGLZgBBi"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Loading and Preprocessing"
      ],
      "metadata": {
        "id": "uI2g-C2_g1GI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_image(img_path, config):\n",
        "  img = load_img(img_path, target_size=config[\"input_size\"])\n",
        "  img_array = img_to_array(img)\n",
        "  img_array = np.expand_dims(img_array, axis=0)\n",
        "  img_array = config[\"preprocess\"](img_array)\n",
        "  return img_array, np.array(img)"
      ],
      "metadata": {
        "id": "Zog0ExfMg3v7"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Grad-CAM For All Models"
      ],
      "metadata": {
        "id": "HyPagY3QhH-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"/content/sample_cell.png\"\n",
        "results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "  config = model_configs[model_name]\n",
        "  img_array, orig_img = load_and_preprocess_image(img_path, config)\n",
        "\n",
        "  preds = model.predict(img_array)\n",
        "\n",
        "  # If the model outputs 1 neuron with sigmoid:\n",
        "  if preds.shape[1] == 1:\n",
        "      pred_class = 0 if preds[0][0] < 0.5 else 1\n",
        "  else:\n",
        "      pred_class = np.argmax(preds[0])\n",
        "\n",
        "\n",
        "  heatmap = make_gradcam_heatmap(\n",
        "      img_array,\n",
        "      model,\n",
        "      last_conv_layer_name=config[\"last_conv\"],\n",
        "      pred_index=pred_class\n",
        "  )\n",
        "\n",
        "  heatmap = cv2.resize(heatmap, config[\"input_size\"])\n",
        "  heatmap = np.uint8(255 * heatmap)\n",
        "  heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "  superimposed = cv2.addWeighted(orig_img, 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "  results[model_name] = superimposed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "_4UF1SYohKwa",
        "outputId": "a9699628-a606-4cfa-d75e-417c103737d7"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-608887149.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   heatmap = make_gradcam_heatmap(\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1840102095.py\u001b[0m in \u001b[0;36mmake_gradcam_heatmap\u001b[0;34m(img_array, model, last_conv_layer_name, pred_index)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Global average pooling and heatmap math\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mpooled_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mconv_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_outputs\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mpooled_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add Grad-CAM Function"
      ],
      "metadata": {
        "id": "j-2iJXfDYiqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "  # Ensure the model is built by calling it with input data\n",
        "  _ = model(img_array)\n",
        "\n",
        "  grad_model = tf.keras.models.Model(\n",
        "      [model.input], # Changed from model.inputs to model.input\n",
        "      [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "  )\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    conv_outputs, predictions = grad_model(img_array)\n",
        "    if pred_index is None:\n",
        "      pred_index = tf.argmax(predictions[0])\n",
        "\n",
        "    if predictions.shape[1] == 1:\n",
        "      class_channel = predictions[:, 0]  # single neuron output\n",
        "    else:\n",
        "      class_channel = predictions[:, pred_index]\n",
        "\n",
        "\n",
        "  grads = tape.gradient(class_channel, conv_outputs)\n",
        "  pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "  conv_outputs = conv_outputs[0]\n",
        "  heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "  heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "  heatmap = tf.maximum(heatmap, 0) # Corrected typo: tf.maxium -> tf.maximum\n",
        "  heatmap /= tf.math.reduce_max(heatmap) + 1e-8\n",
        "  return heatmap.numpy()"
      ],
      "metadata": {
        "id": "L-64cbljYloO"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Preprocess Test Images"
      ],
      "metadata": {
        "id": "XJVpr_P-bQZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"/content/sample_cell.png\"\n",
        "\n",
        "img = load_img(img_path, target_size=(128, 128))\n",
        "img_array = img_to_array(img)\n",
        "img_array = img_array / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n"
      ],
      "metadata": {
        "id": "EvnAOkjubYBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate and Overlay Grad-CAM"
      ],
      "metadata": {
        "id": "DIYj9NCndTYt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "heatmap = make_gradcam_heatmap(\n",
        "  img_array,\n",
        "  model,\n",
        "  last_conv_layer_name=\"Conv_1\""
      ],
      "metadata": {
        "id": "XsNJrR8ZdVhY"
      }
    }
  ]
}